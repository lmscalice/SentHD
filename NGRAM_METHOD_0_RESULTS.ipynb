{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NGRAM HDC METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Basic Packages\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tabulate import tabulate\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Insights and Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Sentiment140 Twitter Dataset...\n",
      "Total number of Samples In Dataset: 1599999\n"
     ]
    }
   ],
   "source": [
    "### Function: Collects sample data from files in Stanford Dataset Subfolders\n",
    "    ## Inputs: folderpath: Path to Desired Folder\n",
    "    ##         sentiment:  Sentiment Value (0 or 1)\n",
    "    ## Output: df: Pandas Dataframe of all Sample Data found in desired folder\n",
    "def stanfordDatasetFolderDataLoader(folderpath, sentiment):\n",
    "    file_list=listdir(folderpath)\n",
    "\n",
    "    df = pd.DataFrame(columns = ['Review', 'Sentiment'])\n",
    "    for file in file_list:\n",
    "        filepath=folderpath + file\n",
    "        f = open(filepath,'r', encoding=\"utf-8\")\n",
    "        sample = f.read()\n",
    "        f.close()\n",
    "        df = df.append({'Review' : sample, 'Sentiment' : sentiment}, ignore_index = True)\n",
    "    return df\n",
    "\n",
    "# Choose Dataset (0: Sentiment140, 1: Stanford IMBD Dataset)\n",
    "dataset = 0\n",
    "\n",
    "# Load Dataset\n",
    "if (dataset==0):\n",
    "    print('Using Sentiment140 Twitter Dataset...')\n",
    "    # Read in Sentiment140 data from CSV\n",
    "    df = pd.read_csv('./Sentiment140_Tweets/data.csv')\n",
    "    df.columns =['Sentiment', 'IDs', 'Date', 'Flag', 'User', 'Tweet']\n",
    "else:\n",
    "    print('Using Stanford IMBD Movie Review Dataset...')\n",
    "    # Read in Training Stanford IMBD Movie Review data from subfolders\n",
    "    train_pos=stanfordDatasetFolderDataLoader('./StanfordMovie/train/pos/',1)\n",
    "    train_neg=stanfordDatasetFolderDataLoader('./StanfordMovie/train/neg/',0)\n",
    "    train_df=pd.concat([train_pos, train_neg], axis=0)\n",
    "    \n",
    "    # Read in Testing Stanford IMBD Movie Review data from subfolders\n",
    "    test_pos=stanfordDatasetFolderDataLoader('./StanfordMovie/test/pos/',1)\n",
    "    test_neg=stanfordDatasetFolderDataLoader('./StanfordMovie/test/neg/',0)\n",
    "    test_df=pd.concat([test_pos, test_neg], axis=0)\n",
    "\n",
    "    df=pd.concat([train_df, test_df], axis=0)\n",
    "print('Total number of Samples In Dataset:', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset in Use has No NULL values.\n",
      "Dataset Length after Cleanup: 1599999\n"
     ]
    }
   ],
   "source": [
    "# Dataset Cleanup:\n",
    "\n",
    "# Sentiment140 Sentiment Clean Up\n",
    "if dataset==0:\n",
    "    # Replace Sentiment of 4 (Positive) with 1\n",
    "    df[\"Sentiment\"].replace({4: 1}, inplace=True)\n",
    "    # Eliminate Neutral Tweets, if any\n",
    "    df = df[df['Sentiment'] != 2]\n",
    "\n",
    "# Check for Null Values\n",
    "if ( not df.isnull().values.any() ):\n",
    "    print(\"Dataset in Use has No NULL values.\")\n",
    "else:\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "print(\"Dataset Length after Cleanup:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>IDs</th>\n",
       "      <th>Date</th>\n",
       "      <th>Flag</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1016244</th>\n",
       "      <td>1</td>\n",
       "      <td>1881672289</td>\n",
       "      <td>Fri May 22 05:16:44 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>viry_trivium</td>\n",
       "      <td>Happy birthday, sister!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303317</th>\n",
       "      <td>1</td>\n",
       "      <td>2009051656</td>\n",
       "      <td>Tue Jun 02 15:04:22 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Earlthedog</td>\n",
       "      <td>Just finished eating supper and now I am attac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576684</th>\n",
       "      <td>0</td>\n",
       "      <td>2211886069</td>\n",
       "      <td>Wed Jun 17 13:24:27 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>StefyyMarie</td>\n",
       "      <td>i hate love right now.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837327</th>\n",
       "      <td>1</td>\n",
       "      <td>1558734942</td>\n",
       "      <td>Sun Apr 19 09:15:07 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tezzer57</td>\n",
       "      <td>Photo fest in LDN, Tudor feast last night, don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985344</th>\n",
       "      <td>1</td>\n",
       "      <td>1834470136</td>\n",
       "      <td>Mon May 18 03:03:30 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>dave_sherratt</td>\n",
       "      <td>@piercedbrat happy bday for tomoz, all the bes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369789</th>\n",
       "      <td>1</td>\n",
       "      <td>2050886442</td>\n",
       "      <td>Fri Jun 05 19:28:18 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>thaisprudencio</td>\n",
       "      <td>today was awesome!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587089</th>\n",
       "      <td>0</td>\n",
       "      <td>2216194514</td>\n",
       "      <td>Wed Jun 17 19:09:39 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>alwyshoutashley</td>\n",
       "      <td>I wish it would stop raining. I'm ready for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46597</th>\n",
       "      <td>0</td>\n",
       "      <td>1677444411</td>\n",
       "      <td>Sat May 02 02:06:29 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>kasey79</td>\n",
       "      <td>@DannyGirlAlways Ok I still feel kind of bad t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409132</th>\n",
       "      <td>1</td>\n",
       "      <td>2055829198</td>\n",
       "      <td>Sat Jun 06 10:01:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Bockman13</td>\n",
       "      <td>Hanging with Anna and Fernando!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984326</th>\n",
       "      <td>1</td>\n",
       "      <td>1834375043</td>\n",
       "      <td>Mon May 18 02:41:35 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AberdeenUK</td>\n",
       "      <td>Good morning everyone. FYI bought him Rock Ban...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sentiment         IDs                          Date      Flag  \\\n",
       "1016244          1  1881672289  Fri May 22 05:16:44 PDT 2009  NO_QUERY   \n",
       "1303317          1  2009051656  Tue Jun 02 15:04:22 PDT 2009  NO_QUERY   \n",
       "576684           0  2211886069  Wed Jun 17 13:24:27 PDT 2009  NO_QUERY   \n",
       "837327           1  1558734942  Sun Apr 19 09:15:07 PDT 2009  NO_QUERY   \n",
       "985344           1  1834470136  Mon May 18 03:03:30 PDT 2009  NO_QUERY   \n",
       "...            ...         ...                           ...       ...   \n",
       "1369789          1  2050886442  Fri Jun 05 19:28:18 PDT 2009  NO_QUERY   \n",
       "587089           0  2216194514  Wed Jun 17 19:09:39 PDT 2009  NO_QUERY   \n",
       "46597            0  1677444411  Sat May 02 02:06:29 PDT 2009  NO_QUERY   \n",
       "1409132          1  2055829198  Sat Jun 06 10:01:49 PDT 2009  NO_QUERY   \n",
       "984326           1  1834375043  Mon May 18 02:41:35 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    User                                              Tweet  \n",
       "1016244     viry_trivium                           Happy birthday, sister!   \n",
       "1303317       Earlthedog  Just finished eating supper and now I am attac...  \n",
       "576684       StefyyMarie                            i hate love right now.   \n",
       "837327          tezzer57  Photo fest in LDN, Tudor feast last night, don...  \n",
       "985344     dave_sherratt  @piercedbrat happy bday for tomoz, all the bes...  \n",
       "...                  ...                                                ...  \n",
       "1369789   thaisprudencio                                today was awesome!   \n",
       "587089   alwyshoutashley  I wish it would stop raining. I'm ready for th...  \n",
       "46597            kasey79  @DannyGirlAlways Ok I still feel kind of bad t...  \n",
       "1409132        Bockman13                   Hanging with Anna and Fernando!   \n",
       "984326        AberdeenUK  Good morning everyone. FYI bought him Rock Ban...  \n",
       "\n",
       "[5000 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downsample the Dataset to 5000 Total Samples\n",
    "percentage=5000/len(df)\n",
    "df_downsampled = df.sample(frac=percentage,random_state=0)\n",
    "df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where Sentiment is Positive when Sentiment Value = 1 and Negative when Sentiment Value = 0\n"
     ]
    }
   ],
   "source": [
    "# Visualization of Dataset Sentiment Outcomes - Ensured Even Distribution of Outcomes\n",
    "sent_count = df_downsampled['Sentiment'].value_counts()\n",
    "plt.figure(figsize=(8, 5))\n",
    "w = 0.35  \n",
    "plt.bar(x=np.arange(len(sent_count)), height=sent_count, width = w)\n",
    "plt.xticks(np.arange(len(sent_count)), sent_count.index.tolist())\n",
    "\n",
    "if dataset==0:\n",
    "    plt.xlabel('Tweet Sentiment Value')\n",
    "    plt.ylabel('Tweet Sentiment Value Count')\n",
    "    plt.title('Sentiment140 Twitter Dataset Sentiment Value Frequency')\n",
    "else:\n",
    "    plt.xlabel('Movie Review Sentiment Value')\n",
    "    plt.ylabel('Movie Review Sentiment Value Count')\n",
    "    plt.title('Stanford IMBD Movie Review Dataset Sentiment Value Frequency')\n",
    "plt.show()\n",
    "print('Where Sentiment is Positive when Sentiment Value = 1 and Negative when Sentiment Value = 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 29, -1, 11, -1, 29, 19, 24, 17, 22, 15, -1, 22, 11, 14, 35, -1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Function: Encodes Characters in Samples to Numerical Values\n",
    "    ## Input: SamplesArray: Array of Samples with Characters\n",
    "    ## Output: X_: Array of Samples with Numberical Values\n",
    "def charEnc(SamplesArray):\n",
    "    X_ = []\n",
    "    for sample in SamplesArray:\n",
    "            token_item = []\n",
    "            for letter in sample.lower():\n",
    "                if ord(letter) >= ord('a') and ord(letter) <= ord('z'):\n",
    "                    token_item.append(ord(letter) - ord('a') + 11)\n",
    "                elif ord(letter) >= ord('0') and ord(letter) <= ord('9'):\n",
    "                    token_item.append(ord(letter) - ord('0') + 1)\n",
    "                elif letter == ' ':\n",
    "                    token_item.append(-1)\n",
    "                else:\n",
    "                    pass\n",
    "            X_.append(token_item)\n",
    "    return X_\n",
    "\n",
    "# Encode the Samples\n",
    "if dataset==0:\n",
    "    Xdf = charEnc(df_downsampled['Tweet'])\n",
    "else:\n",
    "    Xdf = charEnc(df_downsampled['Review'])\n",
    "\n",
    "# Get Final Train/Test Sets:\n",
    "TrainXdf,TestXdf, TrainYdf, TestYdf = train_test_split(Xdf, df_downsampled['Sentiment'],test_size=.2, random_state=2)\n",
    "TrainYdf=np.array(TrainYdf)\n",
    "TestYdf=np.array(TestYdf)\n",
    "TrainXdf[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training Initialization\n",
    "### Item Memory Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1,  1, -1, ..., -1, -1,  1],\n",
       "       [-1, -1, -1, ..., -1,  1,  1],\n",
       "       [ 1,  1,  1, ...,  1, -1, -1],\n",
       "       ...,\n",
       "       [ 1, -1, -1, ..., -1, -1, -1],\n",
       "       [-1,  1, -1, ...,  1,  1, -1],\n",
       "       [ 1,  1,  1, ..., -1, -1, -1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Function: Item Memory Generation\n",
    "    ## Inputs: dim: Number of columns (i.e. length of HV)\n",
    "    ##         num_char: Number of rows (i.e. number of supported chars)\n",
    "    ## Output: dictMem: Item Memory containing HVs for each supported char\n",
    "def itemMemGen(dim=10000, num_char=37):\n",
    "    dictMem = np.random.randint(2, size=(num_char, dim), dtype='int32')\n",
    "    dictMem[dictMem == 0] = -1\n",
    "    return dictMem\n",
    "\n",
    "# Parameters:\n",
    "HV_dim = 10000\n",
    "num_supported_chars = 37\n",
    "\n",
    "# Item Memory Generation\n",
    "itemMem = itemMemGen(dim=HV_dim, num_char=num_supported_chars)\n",
    "itemMem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function: Encodes a Sample into a HV using NGRAM HDC Approach\n",
    "    ## Inputs: sample:      Training Sample\n",
    "    ##         itemMem:     Generate Item Memory\n",
    "    ##         HV_dim:      Dimension of HV\n",
    "    ##         n_gram_len:  Length of NGRAM\n",
    "    ##         window_size: Size of sliding window\n",
    "    ## Output: sample_HV: HV of inputted sample \n",
    "def encode(sample, itemMem, HV_dim=10000, n_gram_len=3, window_size=3):\n",
    "    sample_HV = np.zeros(HV_dim, dtype='int32')\n",
    "\n",
    "    for ngram_start in range(0, len(sample)-n_gram_len+1, window_size):\n",
    "        roll_value=n_gram_len-1\n",
    "        for j in range(n_gram_len):\n",
    "            letterHV = itemMem[sample[ngram_start + j]]\n",
    "\n",
    "            if (j==0):\n",
    "                product = np.roll(letterHV,roll_value)\n",
    "            elif (j==n_gram_len-1):\n",
    "                product = product * letterHV\n",
    "                sample_HV = np.add(sample_HV, product)\n",
    "            else:\n",
    "                product = product * np.roll(letterHV, roll_value)\n",
    "                \n",
    "            roll_value = roll_value - 1\n",
    "\n",
    "    HV_avg = np.average(sample_HV)\n",
    "    sample_HV[sample_HV > HV_avg] = 1\n",
    "    sample_HV[sample_HV < HV_avg] = -1\n",
    "    sample_HV[sample_HV == HV_avg] = 0\n",
    "    return sample_HV\n",
    "\n",
    "### Function: NGRAM HDC Training Function that creates an Associative Memory for the Model\n",
    "    ## Inputs: X:           Training Samples\n",
    "    ##         Y:           Outputs of Training Samples\n",
    "    ##         itemMem:     Generated Item Memory\n",
    "    ##         HV_dim:      Dimension of HV\n",
    "    ##         sent_count:  Number of Possible Sentiment Values\n",
    "    ##         n_gram_len:  Length of NGRAM\n",
    "    ##         window_size: Size of sliding window\n",
    "    ## Output: assocMem: Associative Memory \n",
    "def train(X, Y, itemMem, HV_dim, sent_count, n_gram_len, window_size):\n",
    "    assocMem = np.zeros((sent_count, HV_dim), dtype='int32')\n",
    "    sample_idx = 0\n",
    "    \n",
    "    for sample in X:\n",
    "        sample_HV = encode(sample, itemMem, HV_dim, n_gram_len)\n",
    "        assocMem[Y[sample_idx]] = np.add(assocMem[Y[sample_idx]], sample_HV)\n",
    "        sample_idx += 1\n",
    "    return assocMem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function: Compares Input HV to Class HVs and Returns the Predicted Class\n",
    "    ## Inputs: assocMem: Model's Associative Memory\n",
    "    ##         inputHV:  Encoded HV of a sample\n",
    "    ## Output: pred: the predicted class\n",
    "def get_prediction(assocMem, inputHV):\n",
    "    pred = assocMem[0]\n",
    "    maximum = np.NINF\n",
    "\n",
    "    for index in range(len(assocMem)):\n",
    "        similarity = cosine_similarity([inputHV, assocMem[index]])[0][1]  \n",
    "        if (similarity > maximum):\n",
    "            pred = index\n",
    "            maximum = similarity\n",
    "\n",
    "    return pred\n",
    "\n",
    "### Function: Tests the NGRAM HDC Model and Returns Accuracy of Model\n",
    "    ## Inputs: HV_dim:      Dimension of HV\n",
    "    ##         n_gram_len:  Length of NGRAM\n",
    "    ##         window_size: Size of sliding window\n",
    "    ##         itemMem:     Generated Item Memory\n",
    "    ##         assocMem:    Model's Associative Memory\n",
    "    ##         TestXdf:     Test Samples\n",
    "    ##         TextYdf:     Sentiment of Test Samples\n",
    "    ## Output: accuracy: Accuracy of the Model\n",
    "def test(HV_dim, n_gram_len, window_size, itemMem, assocMem, TestXdf, TestYdf):\n",
    "    true_pos_count=0\n",
    "    false_pos_count=0\n",
    "    correct_count = 0\n",
    "\n",
    "    for index in range(len(TestXdf)):\n",
    "        prediction = get_prediction(assocMem, encode(TestXdf[index], itemMem, HV_dim, n_gram_len, window_size))\n",
    "        if (TestYdf[index] == prediction):\n",
    "            correct_count += 1\n",
    "            if prediction==1:\n",
    "                true_pos_count += 1\n",
    "        elif prediction==1:\n",
    "            false_pos_count += 1 \n",
    "            \n",
    "    accuracy = (correct_count / len(TestYdf)) * 100\n",
    "    if (true_pos_count+false_pos_count) != 0:\n",
    "        precision = (true_pos_count/ (true_pos_count+false_pos_count)) * 100\n",
    "    else:\n",
    "        precision=0\n",
    "    return accuracy, precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Hyperparameter Search\n",
    "### One-Shot Training/Accuracy of Various Sets of Hyperparameter Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Various Hyperparameter Sets\n",
      "  NGRAM LEN    WINDOW SIZE    ONE-SHOT ACCURACY    ONE-SHOT-PRECISION    TRAINING TIME (s)    NUMBER OF TRAINING SAMPLES    TESTING TIME (s)    NUMBER OF TESTING SAMPLES\n",
      "-----------  -------------  -------------------  --------------------  -------------------  ----------------------------  ------------------  ---------------------------\n",
      "          1              1                 47.6                0                   2.89146                          4000             3.32816                         1000\n",
      "          1              1                 47.6                0                   2.57871                          4000             2.90126                         1000\n",
      "          2              1                 63.5               65.3772              6.03674                          4000             5.12829                         1000\n",
      "          2              2                 61.5               63.6008              5.18849                          4000             2.82536                         1000\n",
      "          3              1                 67.6               70.7469              8.12751                          4000             6.83189                         1000\n",
      "          3              3                 67.5               70.8595              7.96161                          4000             3.07699                         1000\n",
      "          4              1                 65.3               69.1974             10.9407                           4000             9.76701                         1000\n",
      "          4              4                 56.5               59.2516             11.3396                           4000             3.30525                         1000\n",
      "          5              1                 65.7               68.4318             14.0198                           4000            12.3962                          1000\n",
      "          5              5                 55.5               57.7299             13.7219                           4000             3.39296                         1000\n",
      "\n",
      "Best Hyperparameters: NGRAM LEN:  3 , WINDOW SIZE:  1\n",
      "Best One-Shot Accuracy:  67.60000000000001\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "n_gram_lens = [1, 2, 3, 4, 5]\n",
    "window_sizes = [1, 0] # Option 0 is the current NGRAM length\n",
    "\n",
    "# Optimal Result Initialization\n",
    "best_acc=0\n",
    "n_gram_best=0\n",
    "window_size_best=0\n",
    "best_assocMem=[]\n",
    "\n",
    "# Generate Table Initialization\n",
    "table_data=[]\n",
    "col_names = [\"NGRAM LEN\", \"WINDOW SIZE\", \"ONE-SHOT ACCURACY\", \"ONE-SHOT-PRECISION\", \"TRAINING TIME (s)\", \"NUMBER OF TRAINING SAMPLES\", \"TESTING TIME (s)\", \"NUMBER OF TESTING SAMPLES\"]\n",
    "\n",
    "for ngram_len in n_gram_lens:\n",
    "    for window_size in window_sizes:\n",
    "\n",
    "        # Option 0:\n",
    "        if window_size==0:\n",
    "            window_size=ngram_len\n",
    "\n",
    "        # Train Model (i.e. Generate Model's Associative Memory)\n",
    "        t0=time.time()\n",
    "        assocMem = train(TrainXdf, TrainYdf, itemMem, HV_dim, len(sent_count), ngram_len, window_size=window_size)\n",
    "        t1=time.time()\n",
    "        train_time = t1-t0\n",
    "\n",
    "        # One-Shot Training Results\n",
    "        t0=time.time()\n",
    "        one_shot_accuracy, one_shot_precision =test(HV_dim, ngram_len, window_size, itemMem, assocMem, TestXdf, TestYdf)\n",
    "        t1=time.time()\n",
    "        test_time = t1-t0\n",
    "\n",
    "        # Add Data to Table\n",
    "        data = [ngram_len, window_size, one_shot_accuracy, one_shot_precision, train_time, len(TrainYdf), test_time, len(TestYdf)]\n",
    "        table_data.append(data)\n",
    "\n",
    "        if one_shot_accuracy>best_acc:\n",
    "            best_acc=one_shot_accuracy\n",
    "            best_assocMem=copy.copy(assocMem)\n",
    "            n_gram_best=ngram_len\n",
    "            window_size_best=window_size\n",
    "\n",
    "# Get Best Assoc Memory\n",
    "assocMem=copy.copy(best_assocMem)\n",
    "\n",
    "# Save Results to File\n",
    "df=pd.DataFrame(table_data, columns=col_names)\n",
    "filepath=\"./Results/HyperparameterResults/NGRAM_\" + str(dataset) +\".csv\"\n",
    "df.to_csv(filepath)\n",
    "\n",
    "print(\"Results of Various Hyperparameter Sets\")\n",
    "print(tabulate(table_data, headers=col_names, tablefmt=\"simple\"))\n",
    "print(\"\\nBest Hyperparameters: NGRAM LEN: \", n_gram_best, \", WINDOW SIZE: \", window_size_best)\n",
    "print(\"Best One-Shot Accuracy: \", best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining Optimal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Retraining Model w Learning Parameter:  20  Epochs --------\n",
      "Epoch  1 :  64.0\n",
      "Epoch  2 :  67.10000000000001\n",
      "Epoch  3 :  67.2\n",
      "Epoch  4 :  66.9\n",
      "Epoch  5 :  67.60000000000001\n",
      "Epoch  6 :  66.4\n",
      "Epoch  7 :  67.10000000000001\n",
      "Epoch  8 :  67.30000000000001\n",
      "Epoch  9 :  66.4\n",
      "Epoch  10 :  66.9\n",
      "Epoch  11 :  67.0\n",
      "Epoch  12 :  67.10000000000001\n",
      "Epoch  13 :  67.0\n",
      "Epoch  14 :  67.10000000000001\n",
      "Epoch  15 :  67.10000000000001\n",
      "Epoch  16 :  67.10000000000001\n",
      "Epoch  17 :  67.10000000000001\n",
      "Epoch  18 :  67.10000000000001\n",
      "Epoch  19 :  67.10000000000001\n",
      "Epoch  20 :  67.10000000000001\n",
      "-------- Retraining Model without Learning Parameter:  20  Epochs --------\n",
      "Epoch  1 :  67.0\n",
      "Epoch  2 :  68.60000000000001\n",
      "Epoch  3 :  66.4\n",
      "Epoch  4 :  66.3\n",
      "Epoch  5 :  67.0\n",
      "Epoch  6 :  66.9\n",
      "Epoch  7 :  67.80000000000001\n",
      "Epoch  8 :  68.60000000000001\n",
      "Epoch  9 :  68.4\n",
      "Epoch  10 :  67.4\n",
      "Epoch  11 :  66.3\n",
      "Epoch  12 :  68.10000000000001\n",
      "Epoch  13 :  68.8\n",
      "Epoch  14 :  67.5\n",
      "Epoch  15 :  68.2\n",
      "Epoch  16 :  68.4\n",
      "Epoch  17 :  68.0\n",
      "Epoch  18 :  68.60000000000001\n",
      "Epoch  19 :  67.80000000000001\n",
      "Epoch  20 :  67.9\n"
     ]
    }
   ],
   "source": [
    "### Function: NGRAM HDC Re-Training Function that creates a New Associative Memory for the Model\n",
    "    ## Inputs: X:           Training Samples\n",
    "    ##         Y:           Outputs of Training Samples\n",
    "    ##         itemMem:     Generated Item Memory\n",
    "    ##         assocMem:    Associative Memory of Current Model\n",
    "    ##         HV_dim:      Dimension of HV\n",
    "    ##         n_gram_len:  Length of NGRAM\n",
    "    ##         window_size: Size of sliding window\n",
    "    ##         alpha:       Learning Rate Parameter\n",
    "    ## Output: assocMem: New Associative Memory\n",
    "def retrain(X, Y, itemMem, assocMem, HV_dim, n_gram_len, window_size, alpha):\n",
    "    sample_index = 0\n",
    "    for sample in X:\n",
    "        sample_HV = encode(sample, itemMem, HV_dim, n_gram_len, window_size)\n",
    "        prediction = get_prediction(assocMem, sample_HV)\n",
    "        if prediction != Y[sample_index]:\n",
    "            assocMem[Y[sample_index]] = np.add(assocMem[Y[sample_index]], alpha * sample_HV)\n",
    "            assocMem[prediction] = np.subtract(assocMem[prediction], alpha * sample_HV)\n",
    "        sample_index += 1\n",
    "    return assocMem\n",
    "\n",
    "# Re-Train Optimal Model with Learning Parameter\n",
    "learningparam_results=[]\n",
    "num_epochs = 20\n",
    "print('-------- Retraining Model w Learning Parameter: ', num_epochs, ' Epochs --------')\n",
    "for epoch in range(num_epochs):\n",
    "    assocMem = retrain(TrainXdf, TrainYdf, itemMem, assocMem, HV_dim, n_gram_best, window_size_best, alpha = num_epochs - epoch)\n",
    "    acc, prec = test(HV_dim, n_gram_best, window_size_best, itemMem, assocMem, TestXdf, TestYdf)\n",
    "    print('Epoch ', (epoch+1), ': ', acc)\n",
    "    learningparam_results.append([acc,prec])\n",
    "\n",
    "# Re-Train Optimal Model without Learning Parameter\n",
    "assocMem=copy.copy(best_assocMem)\n",
    "no_learningparam_results=[]\n",
    "print('-------- Retraining Model without Learning Parameter: ', num_epochs, ' Epochs --------')\n",
    "for epoch in range(num_epochs):\n",
    "    assocMem = retrain(TrainXdf, TrainYdf, itemMem, assocMem, HV_dim, n_gram_best, window_size_best, alpha = 1)\n",
    "    acc, prec = test(HV_dim, n_gram_best, window_size_best, itemMem, assocMem, TestXdf, TestYdf)\n",
    "    print('Epoch ', (epoch+1), ': ', acc)\n",
    "    no_learningparam_results.append([acc,prec])\n",
    "\n",
    "# Save All Results to Files\n",
    "col_name=[\"Accuracy\", \"Precision\"]\n",
    "\n",
    "df_lp=pd.DataFrame(learningparam_results, columns=col_name)\n",
    "filepath=\"./Results/EpochResults_LearningParam/NGRAM_\" + str(dataset) +\".csv\"\n",
    "df_lp.to_csv(filepath)\n",
    "\n",
    "df_nlp=pd.DataFrame(no_learningparam_results, columns=col_name)\n",
    "filepath=\"./Results/EpochResults_NoLearningParam/NGRAM_\" + str(dataset) +\".csv\"\n",
    "df_nlp.to_csv(filepath)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "071eaeccc96c6410cecdb330bf8e8ae0267d24b86e05481c728d399cbe7cbc33"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('aml': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
